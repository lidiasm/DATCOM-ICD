---
title: "Ejercicios de Regresión"
author: "Lidia Sánchez Mérida"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Cargamos las librerías para los ejercicios
require(ISLR)
require(MASS)
require(kknn)
library(ISLR)
library(MASS)
library(kknn)

# Semilla global para reproducir los resultados
set.seed(0)
```

# Ejercicio 1

En este ejercicio el objetivo es replicar el estudio realizado en el `Script1.R` de la asignatura pero sobre el conjunto de datos `california.dat`. Para ello analizaremos sus variables y entrenaremos diferentes modelos con Regresión Lineal Simple y Múltiple.

```{r}
# Cargamos el dataset `california`
xtra <- read.csv("california.dat", comment.char="@", header = FALSE)
# Asignamos manualmente los nombres de las columnas al dataset
names(xtra) <- c("Longitude", "Latitude", "HousingMedianAge", "TotalRooms", "TotalBedrooms", "Population", "Households", "MedianIncome", "MedianHouseValue")
# Representamos todos los predictores con respecto a la variable a predecir para ver si hay algún tipo de relación
plotY <- function (x,y) {
  plot(xtra[,y]~xtra[,x], xlab=paste(names(xtra)[x], sep=""), ylab=names(xtra)[y])
}
par(mfrow=c(3,3)) 
x <- sapply(1:(dim(xtra)[2]-1), plotY, dim(xtra)[2])
```
En el gráfico anterior podemos apreciar que existe una relación creciente entre las últimas cinco variables representadas con respecto a la variable a predecir `MedianHouseValue`. El motivo es que se puede visualizar una tendencia al alza de los valores de la variable independiente conforme aumentan los valores de estas cinco variables en cada una de sus gráficas. 

A continuación vamos a generar cinco modelos diferentes para cada una de las variables destacadas anteriormente utilizando **Regresión Lineal**.

```{r}
# Primer modelo de Regresión Lineal: TotalRooms~Y
xtra.lm1 <- lm(MedianHouseValue~TotalRooms, data=xtra)
summary(xtra.lm1)
# Representamos la función estimada
par(mfrow=c(2,1))
plot(MedianHouseValue~TotalRooms, xtra)
abline(xtra.lm1, col="red")
# Obtenemos los intervalos de confianza
confint(xtra.lm1)
```
Como podemos comprobar, según el p-valor obtenido en el estadístico F la variable `TotalRooms` está relacionada linealmente con la variable a predecir `MedianHouseValue` a pesar de su bajo valor de R².

```{r}
# Segundo modelo de Regresión Lineal: TotalBredrooms~Y
xtra.lm2 <- lm(MedianHouseValue~TotalBedrooms, data=xtra)
summary(xtra.lm2)
# Representamos la función estimada
par(mfrow=c(2,1))
plot(MedianHouseValue~TotalBedrooms, xtra)
abline(xtra.lm2, col="red")
# Obtenemos los intervalos de confianza
confint(xtra.lm2)
```
En este segundo modelo se ha utilizado un único predictor: `TotalBedrooms`, y como se aprecia en los resultados, parece que su relación con la variable independiente es muy similar al caso anterior.

```{r}
# Tercer modelo de Regresión Lineal: Population~Y
xtra.lm3 <- lm(MedianHouseValue~Population, data=xtra)
summary(xtra.lm3)
# Representamos la función estimada
par(mfrow=c(2,1))
plot(MedianHouseValue~Population, xtra)
abline(xtra.lm3, col="red")
# Obtenemos los intervalos de confianza
confint(xtra.lm3)
```
En este tercer modelo compuesto por el predictor `Population` podemos observar que también existe una relación lineal con la variable a predecir aunque algo menos significativa, en comparación con los dos anteriores modelos puesto que el p-valor del estadístico F es mayor.

```{r}
# Cuarto modelo de Regresión Lineal: Households~Y
xtra.lm4 <- lm(MedianHouseValue~Households, data=xtra)
summary(xtra.lm4)
# Representamos la función estimada
par(mfrow=c(2,1))
plot(MedianHouseValue~Households, xtra)
abline(xtra.lm4, col="red")
# Obtenemos los intervalos de confianza
confint(xtra.lm4)
```
En este cuarto modelo compuesto únicamente por el predictor `Households` también aparece una relación lineal con la variable independiente con una clara significancia estadística por su p-valor menor que el umbral 0,05.

```{r}
# Quinto modelo de Regresión Lineal: MedianIncome~Y
xtra.lm5 <- lm(MedianHouseValue~MedianIncome, data=xtra)
summary(xtra.lm5)
# Representamos la función estimada
par(mfrow=c(2,1))
plot(MedianHouseValue~MedianIncome, xtra)
abline(xtra.lm5, col="red")
# Obtenemos los intervalos de confianza
confint(xtra.lm5)
```
Finalmente, en este quinto modelo en el que solo participa el predictor `MedianIncome` podemos observar, de nuevo, una relación lineal con la variable a predecir por su p-valor menor que el umbral. Sin embargo, a diferencia de los modelos anteriores, en este caso el valor de R² es bastante más elevado, lo cual indica que la relación entre ambas variables es mucho más fuerte. Como parece que este quinto modelo es el mejor que se ha obtenido de todos los experimentos, a continuación calculamos las predicciones sobre el conjunto de entrenamiento y su respectivo RMSE.

```{r}
#  Obtenemos las predicciones sobre el conjunto de entrenamiento
xtra.lm5.preds <- predict(xtra.lm5, xtra)
# Calculamos el RMSE
sqrt(sum(abs(xtra$MedianHouseValue-xtra.lm5.preds)^2)/length(xtra.lm5.preds)) 
```
A continuación vamos a crear un modelo con **Regresión Lineal Múltiple** utilizando todas las variables que se han estudiado hasta el momento. Como podemos observar en los resultados, todos los predictores son altamente significativos puesto que sus p-valores son menores que el umbral. Sin embargo, según el valor de R² este modelo solo puede explicar el 53% de los datos.

```{r}
# Primer modelo con Regresión Lineal Múltiple
xtra.lmm1 <- lm(MedianHouseValue~TotalRooms+TotalBedrooms+Population+Households+MedianIncome, data=xtra)
summary(xtra.lmm1)
```
Con el objetivo de intentar mejorar el modelo anterior, vamos a realizar un segundo experimento incluyendo todas las variables disponibles como predictores a excepción de la variable independiente. Como podemos observar en los resultados, el modelo ha mejorado hasta alcanzar un R² del 64% aproximadamente. Por otro lado, si apreciamos sus p-valores, podemos determinar que todas las variables son estadísticamente significativas y tienen una relación lineal con la variable a predecir.

```{r}
# Segundo modelo con Regresión Lineal Múltiple
xtra.lmm2 <- lm(MedianHouseValue~., data=xtra)
summary(xtra.lmm2)
```
Ahora vamos a añadir algunas **interacciones y términos no lineales** para intentar mejorar el valor de R² del modelo anterior. Comenzamos añadiendo un término cuadrático de la variable `MedianIncome` puesto que con este predictor en solitario se ha conseguido el segundo mejor modelo. Tal y como se observa en los resultados, apenas ha mejorado el valor de R² aunque el nuevo término cuadrático dispone de una gran significancia estadística según su p-valor. Si probamos a aumentar un grado y añadir también un término cúbico sobre la misma variable, podemos apreciar en el cuarto modelo que en este caso sí que mejora el valor de R². Sin embargo, añadiendo un término a la cuarta y entrenando un quinto modelo no obtenemos ninguna mejora.

```{r}
# Tercer modelo con Regresión Lineal Múltiple añadiendo un término cuadrático
xtra.lmm3 <- lm(MedianHouseValue~.+I(MedianIncome^2), data=xtra)
summary(xtra.lmm3)
# Cuarto modelo con Regresión Lineal Múltiple añadiendo un término cúbico
xtra.lmm4 <- lm(MedianHouseValue~.+I(MedianIncome^2)+I(MedianIncome^3), data=xtra)
summary(xtra.lmm4)
# Quinto modelo con Regresión Lineal Múltiple añadiendo un término a la cuarta
xtra.lmm5 <- lm(MedianHouseValue~.+I(MedianIncome^2)+I(MedianIncome^3)+I(MedianIncome^4), data=xtra)
summary(xtra.lmm5)
```
Finalmente obtenemos las predicciones y el RMSE sobre el conjunto de entrenamiento utilizando el cuarto mejor modelo entrenado con Regresión Logística Múltiple e incluyendo un término cuadrático y otro cúbico. 

```{r}
# Obtenemos las predicciones sobre el conjunto de entrenamiento
xtra.lmm4.preds <- predict(xtra.lmm4, xtra)
# Calculamos el RMSE 
sqrt(sum(abs(xtra$MedianHouseValue-xtra.lmm4.preds)^2)/length(xtra.lmm4.preds)) 
```
# Ejercicio 2

Para el segundo ejercicio el objetivo consiste en aplicar el estudio realizado en el `Script2.R` de la asignatura sobre el mismo conjunto de datos anterior: `california.dat`. En esta parte, experimentaremos con el algoritmo KNN aplicando validación cruzada, además de comparar los resultados de diferentes algoritmos mediante tests estadísticos.

En primer lugar vamos a entrenar un modelo con el algoritmo KNN en el que utilizaremos todos los predictores puesto que ha sido una de las mejores fórmulas encontradas hasta el momento. Dejamos la configuración por defecto con K=7, el escalado de los datos y que sea el algoritmo el que busque la mejor función kernel para el dataset. Posteriormente evaluamos la bondad del modelo utilizando el mismo conjunto de entrenamiento. Como podemos observar en los resultados, el **RMSE obtenido con el KNN es el menor** conocido hasta el momento para este dataset, lo cual nos indica que este modelo ha sido capaz de ajustarse mejor a los datos aunque perdiendo cierta interpretabilidad. 

```{r}
# Primer modelo con KNN 
xtra.knn1 <- kknn(MedianHouseValue~., xtra, xtra)
# Visualizamos las predicciones realizadas sobre el conjunto de entrenamiento
plot(xtra$MedianHouseValue~xtra$MedianIncome)
points(xtra$MedianIncome, xtra.knn1$fitted.values, col="blue", pch=20)
# Obtenemos las predicciones sobre el conjunto de entrenamiento y calculamos el RMSE
sqrt(sum((xtra$MedianHouseValue-xtra.knn1$fitted.values)^2)/length(xtra.knn1$fitted.values)) 
```
A continuación entrenamos un segundo modelo utilizando el algoritmo KNN con la fórmula de términos cúbicos y cuadráticos que mejor resultado ha proporcionado con Regresión Lineal Múltiple. Según los resultados, el RMSE ha disminuido en más de 200 puntos por lo que hemos conseguido ajustar más el modelo a los datos de entrenamiento.

```{r}
# Segundo modelo con KNN 
xtra.knn2 <- kknn(MedianHouseValue~.+I(MedianIncome^2)+I(MedianIncome^3), xtra, xtra)
# Visualizamos las predicciones realizadas sobre el conjunto de entrenamiento
plot(xtra$MedianHouseValue~xtra$MedianIncome)
points(xtra$MedianIncome, xtra.knn2$fitted.values, col="blue", pch=20)
# Obtenemos las predicciones sobre el conjunto de entrenamiento y calculamos el RMSE
sqrt(sum((xtra$MedianHouseValue-xtra.knn2$fitted.values)^2)/length(xtra.knn2$fitted.values)) 
```
En esta segunda parte del ejercicio vamos a aplicar **validación cruzada para entrenar varios modelos de Regresión Lineal Múltiple y de KNN** utilizando todos los predictores disponibles para predecir la variable independiente del dataset `california`. El objetivo consiste en comparar la capacidad de generalización media que disponen los modelos entrenados con sendos algoritmos.

```{r}
# Validación cruzada para entrenar varios modelos con Regresión Lineal Múltiple y todos los predictores
nombre <- "california"
run_lm_fold <- function(i, x, tt = "test") {
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@", header=FALSE)
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@", header=FALSE)
  In <- length(names(x_tra)) - 1
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti=lm(Y~.,x_tra)
  yprime=predict(fitMulti,test)
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
lmMSEtrain<-mean(sapply(1:5,run_lm_fold,nombre,"train"))
lmMSEtrain
lmMSEtest<-mean(sapply(1:5,run_lm_fold,nombre,"test"))
lmMSEtest

# Validación cruzada para entrenar varios modelos con KNN y todos los predictores
run_knn_fold <- function(i, x, tt = "test") {
  file <- paste(x, "-5-", i, "tra.dat", sep="")
  x_tra <- read.csv(file, comment.char="@", header=FALSE)
  file <- paste(x, "-5-", i, "tst.dat", sep="")
  x_tst <- read.csv(file, comment.char="@", header=FALSE)
  In <- length(names(x_tra)) - 1
  names(x_tra)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tra)[In+1] <- "Y"
  names(x_tst)[1:In] <- paste ("X", 1:In, sep="")
  names(x_tst)[In+1] <- "Y"
  if (tt == "train") {
    test <- x_tra
  }
  else {
    test <- x_tst
  }
  fitMulti=kknn(Y~.,x_tra,test)
  yprime=fitMulti$fitted.values
  sum(abs(test$Y-yprime)^2)/length(yprime) ##MSE
}
knnMSEtrain<-mean(sapply(1:5,run_knn_fold,nombre,"train"))
knnMSEtrain
knnMSEtest<-mean(sapply(1:5,run_knn_fold,nombre,"test"))
knnMSEtest
```
Como podemos apreciar en los resultados, parece que en media los modelos entrenados con KNN son capaces de minimizar el RMSE frente a los entrenados con Regresión Lineal Múltiple. De este modo, conseguimos un modelo que se ajusta más a los datos, que dispone de una mayor capacidad de generalización, a costa de perder interpretabilidad.

Finalmente, vamos a realizar una **comparativa** entre los resultados obtenidos sobre los conjuntos de entrenamiento y validación de diversos datasets al aplicar los algoritmos de **Regresión Lineal, KNN y M5**. Proponemos a KNN como el mejor candidato para realizar los tests.

```{r}
# Leemos los resultados sobre el conjunto de entrenamiento
resultados <- read.csv("regr_train_alumnos.csv")
tablatra <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatra) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatra) <- resultados[,1]
# Leemos los resultados sobre el conjunto de test
resultados <- read.csv("regr_test_alumnos.csv")
tablatst <- cbind(resultados[,2:dim(resultados)[2]])
colnames(tablatst) <- names(resultados)[2:dim(resultados)[2]]
rownames(tablatst) <- resultados[,1]
# Normalizamos la tabla de resultados de tests para Wilcoxon
# ""+ 0.1 porque wilcox R falla para valores == 0 en la tabla""
difs <- (tablatst[,1] - tablatst[,2]) / tablatst[,1]
wilc_1_2 <- cbind(ifelse (difs<0, abs(difs)+0.1, 0+0.1), ifelse (difs>0, 	abs(difs)+0.1, 0+0.1))
colnames(wilc_1_2) <- c(colnames(tablatst)[1], colnames(tablatst)[2])
head(wilc_1_2)

# Aplicamos el test de Wilcoxon sobre Regresión Lineal y KNN
LMvsKNNtst <- wilcox.test(wilc_1_2[,1], wilc_1_2[,2], alternative = "two.sided", paired=TRUE)
Rmas <- LMvsKNNtst$statistic
pvalue <- LMvsKNNtst$p.value
LMvsKNNtst <- wilcox.test(wilc_1_2[,2], wilc_1_2[,1], alternative = "two.sided", paired=TRUE)
Rmenos <- LMvsKNNtst$statistic
Rmas
Rmenos
pvalue
```
Como podemos apreciar, el p-valor resultante de aplicar el test de Wilcoxon nos revela que **no se puede rechazar la hipótesis nula** de que el algoritmo KNN tiene el mismo comportamiento que Regresión Lineal sobre los datasets probados. Así, se puede determinar que solo existe un 23.4% de confianza de que sean distintos.

A continuación aplicamos el test de Friedman para comparar los tres algoritmos simultáneamente. En este caso, el p-valor devuelto es menor que el umbral=0.05 por lo que **rechazamos la hipótesis de que los tres algoritmos son iguales**. Para determinar cuáles pueden ser los algoritmos que destaquen sobre el resto, vamos a agrupar los algoritmos por pares siendo 1:Regresión Lineal, 2:KNN y 3:M5, de modo que se puedan realizar **múltiples tests de Wilcoxon con una penalización por pasos de Holm** para controlar el error `FWER` acumulado de ejecutar varios tests sobre los mismos datos. Tal y como se aprecia en los resultados, existe una diferencia significativa entre el 1 (Regresión Lineal) y el 3 (M5) puesto que su p-valor está por debajo del umbral=0.05. Sin embargo, también se puede considerar al 90% de confianza aproximadamente que también existen diferencias significativas entre el 2 (KNN) y 3 (M5). Así, podemos concluir que el algoritmo M5 es significativamente distinto de los algoritmos de Regresión Lineal y KNN, mientras que estos dos según su p-valor podrían considerarse iguales.

```{r}
# Aplicamos el test de Friedman para comparar los tres algoritmos simultáneamente
test_friedman <- friedman.test(as.matrix(tablatst))
test_friedman
# Aplicamos un Post Hoc con el test de Wilcoxon y una penalización por pasos de Holm
tam <- dim(tablatst)
groups <- rep(1:tam[2], each=tam[1])
pairwise.wilcox.test(as.matrix(tablatst), groups, p.adjust = "holm", paired = TRUE)
```

