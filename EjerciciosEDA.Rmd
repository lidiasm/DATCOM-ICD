---
title: "Ejercicios EDA"
author: "Lidia Sánchez Mérida"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hip dataset

```{r}
# Descargamos el dataset obteniendo la cabecera y normalizando el tamaño de las filas
#hip<-read.table("https://astrostatistics.psu.edu/datasets/HIP_star.dat", header=T, fill=T)
hip<-read.table("HIP_star.dat", header=T, fill=T)
# Dimensión
dim(hip)
# Nombre de las columnas
colnames(hip)
# Tipos de datos
str(hip)
```
Como se puede visualizar en los resultados anteriores, este dataset dispone de **2.719 muestras y 9 variables**, siendo todas ellas numéricas.

A continuación se calculan las medidas centrales, como la **media, la mediana y la moda**, para cada una de las columnas. Para ello utilizamos la función `apply` con el objetivo de realizar estos cálculos para cada una de las columnas.

```{r}
apply(hip, 2, mean)
apply(hip, 2, median)
apply(hip, 2, mode)
```

En el siguiente `chunk` se calcula el **mínimo y máximo** para cada una de las columnas del dataset. Para ello, seguiremos utilizando la función `apply` en combinación con la función `range`, que proporciona sendos valores en el mismo resultado.

```{r}
apply(hip, 2, range)
```

Ahora calcularemos la **varianza, desviación estándar y la desviación absoluta de la mediana** para la variable `RA`. 

```{r}
var(hip$RA)
sd(hip$RA)
mad(hip$RA)
```
A continuación probamos la función definida en los ejercicios para intentar comprobar si se pueden calcular **la mediana y la desviación absoluta de la mediana**. Y tal y como se puede observar en el siguiente `chunk`, se pueden calcular sin ningún problema.

```{r}
f = function(x) c(median(x), mad(x))  
# Cálculo de la mediana y su desviación absoluta a partir de la 3ª columna
f(hip[,3])
```
En este siguiente `chunk` se realizan los mismos cálculos anteriores pero para la variable `RA` usando el operado `%>%` de la librería **`dplyr`**.

```{r message=FALSE, warning=FALSE}
library(dplyr)
c(hip$RA %>% median(), hip$RA %>% mad())
```
A continuación se propone averiguar cuál sería el resultado de ejecutar **`apply(hip,2,f)`**, siendo `f` la función definida anteriormente para calcular la mediana y su desviación absoluta.

```{r}
apply(hip, 2, f)
```
Como se puede observar en los resultados, el `chunk` anterior calcula la mediana y la desviación absoluta de la mediana para cada una de las columnas del dataset.

Ahora pasamos a calcular el **cuartil 0.10 y 0.50** para la columna `RA` del dataset. Para ello utilizaremos la función `quantile` a la que le especificaremos como vector de probabilidades el cuartil inicial, el final y el número de pasos que debe realizar. Para obtener solo el cuartil 0.1 y 0.5 basta con con situarlos como inicio y fin de la secuencia, estableciendo una suma de 0.4 para no calcular ninguno más.

```{r}
quantile(hip$RA, probs=seq(0.1, 0.5, 0.4))
```
En caso de querer calcular los **cuatro cuartiles** podemos utilizar la misma función, solo que en este caso especificaremos como primer valor el Q1 (0.25) y 0.25 como suma para calcular los restantes.

```{r}
quantile(hip$RA, probs=seq(0.25, 1.0, 0.25))
```
A continuación se propone averiguar si la función `summary` proporciona la **distancia intercuartil**. Para ello la aplicamos sobre la misma variable anterior y como podemos ver en el siguiente `chunk`, esta medida no se proporciona directamente. Sin embargo, se puede calcular mediante la **diferencia del Q3 y del Q1**, gracias a que se pueden obtener dichos valores de manera independiente de los resultados de la función `summary`.

```{r}
hip_summ<-summary(hip$RA)
hip_summ
# Cálculo de IQR a partir de Q3-Q1
as.numeric(hip_summ[5]) - as.numeric(hip_summ[2])
```
El objetivo del siguiente `chunk` es analizar los resultados de la función que se define así como su aplicación al *HIP* dataset. Como se puede apreciar en la salida, esta función indica con un valor `TRUE` si existen valores perdidos para cada una de las columnas, mientras que devuelve `FALSE` en caso de que no se hayan encontrado. Para este dataset solo la **columna `B.V` tiene valores perdidos**.

```{r}
hasNA = function(x) any(is.na(x)) 
apply(hip, 2, hasNA)   
```
Si intentamos obtener el valor mínimo de la columna anterior, que contiene valores perdidos, utilizando la función **`min` nos devolverá `NA` como respuesta**. Para obtener el verdadero mínimo de esta columna deberemos especificar en la función `na.rm=TRUE` para que los ignore durante el proceso.

```{r}
min(hip$B.V)
min(hip$B.V, na.rm = TRUE)
```
Otra forma de hacerlo sería utilizar la función **`na.omit`**, que elimina todas las muestras en las que existan valores perdidos. De este modo podemos calcular el mínimo de la variable `B.V` sin aportar ningún argumento adicional.

```{r}
hip_nan = na.omit(hip)
# Suma de valores perdidos del dataset = 0
sum(is.na(hip_nan))
# Dimensiones del nuevo dataset sin NA
dim(hip_nan)
min(hip_nan$B.V)
```
En el siguiente `chunk` se propone una tercera forma de realizar un cálculo matemático generalizado para todo el dataset sin tener que modificarlo y adaptándose a los valores perdidos de cada columna. En este caso, calcularemos la **media para todas las columnas**, ignorando los valores `NA` existentes. De este modo, la eliminación de valores perdidos solo afectará a las medias de las columnas que dispongan de `NA`, como es el caso de la variable `B.V`.

```{r}
# Medias con el conjunto original
apply(hip, 2, mean)

# Medias con el conjunto original ignorando los NA para cada columna
apply(hip, 2, function(x) mean(x, na.rm=TRUE))
```
A continuación se pretende mostrar un **diagrama de cajas** del dataset al completo para observar la variabilidad de los datos almacenados en cada una de las columnas. En el primer gráfico, podemos observar que solo la variable `HIP` es visible puesto que las cajas de las restantes apenas tienen longitud. Esto puede deberse a sus **diferentes escalas**. Por ello, escalamos y centramos los datos para representar de nuevo el diagrama de cajas.
```{r}
# Diagrama de cajas del conjunto original
var_colors<-c("red", "yellow", "orange", "green", "cyan", "blue", "pink", "purple", "gray")
boxplot(hip, notch=TRUE, col=var_colors)

# Escalamos y centramos los datos
scaled_hip<-scale(hip)
# Diagrama de cajas con los datos normalizados
boxplot(scaled_hip, notch=TRUE, col=var_colors)
```
En el segundo gráfico podemos observar que las cajas de todas las variables se caracterizan por una pequeña longitud, lo que demuestra que **no existe apenas dispersión en los datos**, sino que cada variable está concentrada en un rango de valores particular. Por otro lado, podemos apreciar que algunas variables disponen de **outliers moderados**, excepto `pmDE` y `e_Plx` cuyos número de *outliers* es mayor así como su lejanía con respecto a la concentración de valores. Según la descripción de este dataset, de este gráfico podemos concluir que **las coordenadas de la longitud (`RA`) no están relacionadas con las de la latitud (`DE`)**.

A continuación, se muestra una **gráfica de puntos entre las variables `RA` y `DE`**, mostrando en color rojo aquellos puntos cuyo `DE` sea mayor que 0. Como podemos observar, no existe ninguna relación visible entre sendas variables puesto que en el gráfico representado no se aprecia ninguna distribución conocida.

```{r}
library(ggplot2)
ggplot(hip, aes(x=RA, y=DE)) + geom_point(color=ifelse(hip$DE > 0,'red','gray'))
```
Ahora vamos a probar a realizar el mismo gráfico anterior pero entre las variables **`RA` y `pmRA`**. En este caso sí parece existir una **relación cuadrática** entre sendas columnas puesto que la mayoría de los puntos siguen la forma de esta función, exceptuando algunos *outliers*. De este gráfico podemos concluir que el movimiento de las estrellas por el cielo es decreciente en aquellas longitudes pertenecientes al intervalo [0, 200], mientras que es creciente en la otra mitad.

```{r}
library(ggplot2)
ggplot(hip, aes(x=RA, y=pmRA)) + geom_point(color="orange")
```
En lugar de representar un gráfico de puntos por cada par de variables, utilizaremos la función **`scatterplotMatrix`** para llevarlo a cabo con todas ellas. Como podemos apreciar en los resultados, la mayoría de las variables **parecen no seguir una distribución normal**. Mientras que por otro lado, podemos observar que existen pocas variables relacionadas entre sí en función de los gráficos de puntos. 

```{r warning=FALSE}
library(car)
scatterplotMatrix(hip)
```

Por último, vamos a filtrar el dataset según las condiciones descritas en el ejercicio para crear uno nuevo que solo contenga las **estrellas Hyadas**. A continuación, utilizando este nuevo dataset representamos las variables **`Vmag y B.V`** en un diagrama de puntos.

```{r}
attach(hip)
hyades<-hip %>% filter(RA > 50 & RA < 100) %>% filter(DE > 0 & DE < 25) %>% filter(pmRA > 90 & pmRA < 130) %>% filter(pmDE > -60 & pmDE < -10) %>% filter(e_Plx < 5) %>% filter(Vmag > 4 | B.V < 0.2)
# Dimensiones del nuevo dataset
dim(hyades)
# Diagrama de puntos entre Vmag y B.V
ggplot(hyades, aes(x=Vmag, y=B.V)) + geom_point(color="purple")
```
Tal y como podemos apreciar, parece que existe una **relación lineal** entre ambas variables puesto que los puntos representados siguen una línea recta ascendente, excepto por algunos *outliers moderados*. Por tanto, según la descripción de este dataset y considerando que la luminosidad de las estrellas está invertida, parece que las estrellas que brillan menos tienen más color que las más brillantes.

